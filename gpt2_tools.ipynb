{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966b7432-0d01-4a03-9f16-9f85afd316d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\New folder\\envs\\bots\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "07/24/2023 15:45:43 - INFO - happytransformer.happy_transformer -   Using model: cuda\n",
      "07/24/2023 15:45:45 - INFO - happytransformer.happy_transformer -   Preprocessing dataset...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 67.52it/s]\n",
      "07/24/2023 15:45:47 - INFO - happytransformer.happy_transformer -   Training...\n",
      "D:\\miniconda\\New folder\\envs\\bots\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "D:\\miniconda\\New folder\\envs\\bots\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "D:\\miniconda\\New folder\\envs\\bots\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "D:\\miniconda\\New folder\\envs\\bots\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='650' max='650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [650/650 05:14, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from happytransformer import HappyGeneration, GENTrainArgs, GENSettings\n",
    "# --------------------------------------#\n",
    "\n",
    "happy_gen = HappyGeneration(\"GPT2\", \"MBZUAI/LaMini-GPT-124M\")\n",
    "args = GENTrainArgs(num_train_epochs=50) \n",
    "happy_gen.train(\"train.txt\", args=args)\n",
    "happy_gen.save(\"lamini_tool/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19099047-ae82-4b8d-9e8d-e1b92accdbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\New folder\\envs\\bots\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "07/24/2023 15:57:45 - INFO - happytransformer.happy_transformer -   Using model: cuda\n",
      "D:\\miniconda\\New folder\\envs\\bots\\lib\\site-packages\\transformers\\generation\\utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {  \"action\": \"Wiki\",  \"action_input\": \"Albert Einstein\"}\n",
      "Albert Einstein ( EYEN-styne; German: [ˈalbɛʁt ˈʔaɪnʃtaɪn] (listen); 14 March 1879 – 18 April 1955) was a German-born theoretical physicist, widely ranked among the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His mass–energy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world's most famous equation\". His work is also known for its influence on the philosophy of science. He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His intellectual achievements and originality resulted in \"Einstein\" becoming synonymous with \"genius\". Einsteinium, one of the synthetic elements in the periodic table, was named in his honor.In 1905, a year sometimes described as his annus mirabilis (miracle year), Einstein published four groundbreaking papers. These outlined a theory of the photoelectric effect, explained Brownian motion, introduced his special theory of relativity—a theory which addressed the inability of classical mechanics to account satisfactorily for the behavior of the electromagnetic field—and demonstrated that if the special theory is correct, mass and energy are equivalent to each other. In 1916, he proposed a general theory of relativity that extended his system of mechanics to incorporate gravitation. A cosmological paper that he published the following year laid out the implications of general relativity for the modeling of the structure and evolution of the universe as a whole. The middle part of his career also saw him making important contributions to statistical mechanics and quantum theory. Especially notable was his work on the quantum physics of radiation, which introduced the idea that light consisted of particles, subsequently called photons.\n",
      "For much of the last phase of his academic life, Einstein worked on two endeavors that proved ultimately unsuccessful. Firstly, he fought a long rearguard action against quantum theory's introduction of fundamental randomness into science's picture of the world, objecting that \"God does not play dice\". Secondly, he attempted to devise a unified field theory by generalizing his geometric theory of gravitation to include electromagnetism too. As a result, he became increasingly isolated from the mainstream of modern physics.\n",
      "Born in the German Empire, Einstein moved to Switzerland in 1895, forsaking his German citizenship (as a subject of the Kingdom of Württemberg) the following year. In 1897, at the age of seventeen, he enrolled in the mathematics and physics teaching diploma program at the Swiss Federal polytechnic school in Zürich, graduating in 1900. In 1901, he acquired Swiss citizenship, which he kept for the rest of his life. In 1903, he secured a permanent position at the Swiss Patent Office in Bern. In 1905, he submitted a successful PhD dissertation to the University of Zurich. In 1914, he moved to Berlin in order to join the Prussian Academy of Sciences and the Humboldt University of Berlin. In 1917, he became director of the Kaiser Wilhelm Institute for Physics; he also became a German citizen again, this time as a subject of the Kingdom of Prussia. In 1933, while he was visiting the United States, Adolf Hitler came to power in Germany. Alienated by the policies of the newly elected Nazi government, Einstein decided to remain in the US, and was granted American citizenship in 1940. On the eve of World War II, he endorsed a letter to President Franklin D. Roosevelt alerting him to the potential German nuclear weapons program and recommending that the US begin similar research. Einstein supported the Allies but generally viewed the idea of nuclear weapons with great dismay.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from googlesearch import search\n",
    "from happytransformer import HappyGeneration, GENTrainArgs, GENSettings\n",
    "import math\n",
    "import wikipedia\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, model_type=\"GPT2\", model_name=\"MBZUAI/LaMini-GPT-124M\", load_path=\"lamini_tool/\"):\n",
    "        self.happy_gen = HappyGeneration(model_type, model_name, load_path=load_path)\n",
    "        self.args = GENSettings(max_length=200, temperature=0.0)\n",
    "        self.tool = {\n",
    "            \"Search\" : self.google_search,\n",
    "            \"Calc\" : self.calculator,\n",
    "            \"Chat\" : self.print_action,\n",
    "            \"Time\" : self.get_current_date_time,\n",
    "            \"Wiki\" : self.get_wiki_summary\n",
    "        }\n",
    "    \n",
    "    def print_action(self, string):\n",
    "        print(string)\n",
    "\n",
    "    def calculator(self, expression):\n",
    "        # Make sure math functions can be used in eval\n",
    "        safe_dict = {'sqrt': math.sqrt, '__builtins__': {}}\n",
    "        try:\n",
    "            print(eval(expression, {\"__builtins__\":None}, safe_dict))\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "        \n",
    "    def google_search(self, query, num_results=4):\n",
    "        search_results = search(query, num_results=num_results, lang=\"en\")\n",
    "        for i, result in enumerate(search_results, start=1):\n",
    "            print(f\"{i}. {result}\")\n",
    "\n",
    "    def get_current_date_time(self, string):\n",
    "        now = datetime.now()\n",
    "        formatted_date_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(formatted_date_time)\n",
    "\n",
    "    def get_wiki_summary(self, query):\n",
    "        try:\n",
    "            summary = wikipedia.summary(query)\n",
    "            print(summary)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "    def create_prompt(self, system_prompt, user_query):\n",
    "        return f\"\"\"\n",
    "System: {system_prompt}\n",
    "Human:  {user_query}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "    def exec_tool(self, json_string):\n",
    "        data = json.loads(json_string)\n",
    "        try:\n",
    "            self.tool[data[\"action\"]](data[\"action_input\"])\n",
    "        except:\n",
    "            self.tool[\"Chat\"](data[\"action_input\"])\n",
    "            \n",
    "    def execute(self, system_prompt, user_query):\n",
    "        input_prompt = self.create_prompt(system_prompt, user_query)\n",
    "        result = self.happy_gen.generate_text(input_prompt, args=self.args)\n",
    "        print(result.text)\n",
    "        self.exec_tool(result.text)\n",
    "\n",
    "\n",
    "assistant = Assistant()\n",
    "assistant.execute(\"You are a helpful AI Assistant\", \"Find information about Albert Einstein.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb641202-ff82-470a-996d-0175651cf7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {  \"action\": \"Time\",  \"action_input\": \"current time\"}\n",
      "2023-07-24 15:53:11\n"
     ]
    }
   ],
   "source": [
    "assistant.execute(\"You are a helpful AI Assistant\", \"What time is it currently?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2053c804-c4a8-4c3d-9980-72ff173c214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {  \"action\": \"Search\",  \"action_input\": \"best color\"}\n",
      "1. https://webflow.com/blog/best-color-combinations\n",
      "2. https://99designs.com/blog/creative-inspiration/color-combinations/\n",
      "3. https://www.canva.com/learn/100-color-combinations/\n",
      "4. https://looka.com/blog/color-combinations/\n",
      "5. https://coolors.co/\n",
      "6. https://neilpatel.com/blog/choose-best-color-conversion/\n",
      "7. https://colorhunt.co/\n",
      "8. https://neilpatel.com/blog/choose-best-color-conversion/\n",
      "9. https://coolors.co/\n",
      "10. https://www.oberlo.com/blog/color-combinations-cheat-sheet\n",
      "11. https://colorhunt.co/\n"
     ]
    }
   ],
   "source": [
    "assistant.execute(\"You are a helpful AI Assistant\", \"What is your favorite color?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b28b9c41-6b4a-4ed1-b6e0-7959e80bfb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {  \"action\": \"Calc\",  \"action_input\": \"5 * 6 + 2 / 4\"}\n",
      "30.5\n"
     ]
    }
   ],
   "source": [
    "assistant.execute(\"You are a helpful AI Assistant\", \"Calculator  5 * 6 + 2 / 4?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6a0c247-6101-4a28-ba6b-6e9319f308ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {  \"action\": \"Chat\",  \"action_input\": \"I feel great!\"}\n",
      "I feel great!\n"
     ]
    }
   ],
   "source": [
    "assistant.execute(\"You are a helpful AI Assistant\", \"How do you feel?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c38173-3482-4756-b482-d2ab43e04d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
